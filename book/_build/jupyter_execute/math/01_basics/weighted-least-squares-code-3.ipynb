{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57aca5d",
   "metadata": {},
   "source": [
    "# WLS - Code Examples Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df67100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cd12e",
   "metadata": {},
   "source": [
    "just some notes:\n",
    "\n",
    "Example 1. Non-Linear Example with Y-axis Errors with Negligible Standard Deviation for the First Point\n",
    "\n",
    "Here we assume that the Y-value for x=0 should be equal to 100, so the error for this y data point is close to zero. For the remaining points, we expect errors to be the same and equal to 0.5. Thus, standard deviation is $\\sigma_{i} = 0.5$ for each data point except the first one.\n",
    "\n",
    "We set `sigma` array as `[1e-9, 0.5, 0.5, 0.5, ...]`. The first point with `sigma = 1e-9` gets an extremely large weight, forcing the fitted curve to pass almost exactly through that point. This value is chosen to be practically zero, thereby assigning an exceptionally large weight to this data point in the minimization process, compelling the fitted curve to pass almost exactly through $(x_1, y_1)$.\n",
    "\n",
    "Based on the results, we will see why it was a bad idea to set negligible value of the standard deviation for the first point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff5222",
   "metadata": {},
   "source": [
    "## Example 1. Non-Linear Example with Y-axis Errors\n",
    "\n",
    "`sigma` array is `[0.5, 0.5, 0.5, 0.5, ...]` for all the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26fb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5570093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the function to fit\n",
    "def custom_function(x, A, B):\n",
    "    \"\"\"\n",
    "    The custom function to approximate the data.\n",
    "    f(x; A, B) = A * (np.exp(-B * x) - 1) + 100\n",
    "    \"\"\"\n",
    "    return A * (np.exp(-B * x) - 1) + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c504bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess for parameters A and B\n",
    "initial_guess = [50, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e35929",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 5, 25, 34, 42, 57, 97])\n",
    "y_obs = np.array([100, 79.7, 51.3, 44.6, 39.8, 29.9, 10.3])\n",
    "\n",
    "# Define sigma for Weighted Least Squares\n",
    "sigma = np.full_like(y_obs, 0.5, dtype=float)\n",
    "\n",
    "weights = 1.0 / (sigma**2)\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['x_data'] = x\n",
    "results['y_data'] = y_obs\n",
    "results['sigma'] = sigma\n",
    "results['weights'] = weights\n",
    "\n",
    "# # Dataset 2\n",
    "# x = np.array([0, 19, 45, 104, 191, 294, 391])\n",
    "# y_obs = np.array([100, 80.4, 66.4, 50.1, 41.2, 28.5, 20.1])\n",
    "\n",
    "# # Dataset 3\n",
    "# x = np.array([0, 23, 51, 98, 196, 292, 401])\n",
    "# y_obs = np.array([100, 87.8, 77, 65.7, 50.9, 46.5, 44.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1097357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve_fit returns:\n",
    "# popt: Optimal values for the parameters so that the sum of the squared residuals is minimized.\n",
    "# pcov: The estimated covariance of popt.\n",
    "# Use sigma for weighted least squares\n",
    "popt, pcov, infodict, _, _ = curve_fit(custom_function, x, y_obs, p0=initial_guess, sigma=sigma, absolute_sigma=True, full_output=True)\n",
    "\n",
    "fit_a, fit_b = popt\n",
    "\n",
    "# Standard errors are the sqrt of the diagonal of the covariance matrix\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "std_err_a, std_err_b = perr\n",
    "\n",
    "n = len(x)  # Number of observations\n",
    "p = len(popt) # Number of parameters\n",
    "degrees_of_freedom = n - p # Degrees of Freedom\n",
    "\n",
    "# Generate predicted y values using the fitted function\n",
    "y_pred = custom_function(x, fit_a, fit_b)\n",
    "\n",
    "residuals_calc = y_obs - y_pred\n",
    "\n",
    "weighted_residuals = (y_obs - y_pred) / sigma\n",
    "\n",
    "residuals_scipy = infodict['fvec']\n",
    "\n",
    "results['fit_a'] = fit_a\n",
    "results['fit_b'] = fit_b\n",
    "results['std_err_a'] = std_err_a\n",
    "results['std_err_b'] = std_err_b\n",
    "results['number_of_observations'] = n\n",
    "results['number_of_parameters'] = p\n",
    "results['degrees_of_freedom'] = degrees_of_freedom\n",
    "results['y_pred'] = y_pred\n",
    "results['residuals_calc'] = residuals_calc\n",
    "results['weighted_residuals'] = weighted_residuals\n",
    "results['residuals_scipy'] = residuals_scipy\n",
    "results['condition_number'] = np.linalg.cond(pcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83095b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate t-values\n",
    "t_value_a = fit_a / std_err_a\n",
    "t_value_b = fit_b / std_err_b\n",
    "\n",
    "# Calculate two-tailed p-values\n",
    "p_value_a = stats.t.sf(np.abs(t_value_a), df=degrees_of_freedom) * 2\n",
    "p_value_b = stats.t.sf(np.abs(t_value_b), df=degrees_of_freedom) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c6b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fitted Parameters ---\n",
      "A parameter: 93.5355 +/- 0.8080\n",
      "B parameter: 0.0270 +/- 0.0005\n",
      "Number of Observations (n): 7\n",
      "Number of Parameters (p): 2\n",
      "Degrees of Freedom (degrees_of_freedom): 5\n"
     ]
    }
   ],
   "source": [
    "# Extract the fitted parameters\n",
    "print(\"--- Fitted Parameters ---\")\n",
    "print(f\"A parameter: {fit_a:.4f} +/- {std_err_a:.4f}\")\n",
    "print(f\"B parameter: {fit_b:.4f} +/- {std_err_b:.4f}\")\n",
    "\n",
    "print(f\"Number of Observations (n): {n}\")\n",
    "print(f\"Number of Parameters (p): {p}\")\n",
    "print(f\"Degrees of Freedom (degrees_of_freedom): {degrees_of_freedom}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdee2f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error for A: 0.808014\n",
      "T-value for A: 115.759755\n",
      "P-value for A: 0.000000\n",
      "Standard Error for B: 0.000504\n",
      "T-value for B: 53.507498\n",
      "P-value for B: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard Error for A: {std_err_a:.6f}\")\n",
    "print(f\"T-value for A: {t_value_a:.6f}\")\n",
    "print(f\"P-value for A: {p_value_a:.6f}\")\n",
    "print(f\"Standard Error for B: {std_err_b:.6f}\")\n",
    "print(f\"T-value for B: {t_value_b:.6f}\")\n",
    "print(f\"P-value for B: {p_value_b:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a7a192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sum of Squares (SS) ---\n",
      "\n",
      "Weighted Residual Sum of Squares (Weighted RSS): 444.5407\n",
      "Unweighted Residual Sum of Squares (RSS): 111.1352\n"
     ]
    }
   ],
   "source": [
    "# --- Sum of Squares Calculations ---\n",
    "print(\"\\n--- Sum of Squares (SS) ---\")\n",
    "# Residual Sum of Squares (RSS)\n",
    "rss_unweighted = np.sum(residuals_calc**2)\n",
    "rss_weighted = np.sum(weighted_residuals**2) # This is also the Chi-Squared value\n",
    "print(f\"\\nWeighted Residual Sum of Squares (Weighted RSS): {rss_weighted:.4f}\")\n",
    "print(f\"Unweighted Residual Sum of Squares (RSS): {rss_unweighted:.4f}\")\n",
    "\n",
    "results['rss_unweighted'] = rss_unweighted\n",
    "results['rss_weighted'] = rss_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22fd5c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Centered Total Sum of Squares (TSS): 21970.4000\n",
      "Unweighted Centered Total Sum of Squares (TSS): 5492.6000\n",
      "\n",
      "Weighted Uncentered Total Sum of Squares (TSS): 94228.3200\n",
      "Unweighted Uncentered Total Sum of Squares (TSS): 23557.0800\n",
      "\n",
      "Weighted Explained Sum of Squares (ESS): 24295.5217\n",
      "Unweighted Explained Sum of Squares (ESS): 6073.8804\n"
     ]
    }
   ],
   "source": [
    "# Total Sum of Squares (TSS)\n",
    "weighted_mean_y = np.sum(weights * y_obs) / np.sum(weights)\n",
    "unweighted_mean_y = np.mean(y_obs)\n",
    "weighted_centered_tss = np.sum(weights * (y_obs - weighted_mean_y)**2)\n",
    "unweighted_centered_tss = np.sum((y_obs - unweighted_mean_y)**2)\n",
    "print(f\"\\nWeighted Centered Total Sum of Squares (TSS): {weighted_centered_tss:.4f}\")\n",
    "print(f\"Unweighted Centered Total Sum of Squares (TSS): {unweighted_centered_tss:.4f}\")\n",
    "\n",
    "# Uncentered Total Sum of Squares (TSS)\n",
    "weighted_uncentered_tss = np.sum(weights * (y_obs)**2)\n",
    "unweighted_uncentered_tss = np.sum((y_obs)**2)\n",
    "print(f\"\\nWeighted Uncentered Total Sum of Squares (TSS): {weighted_uncentered_tss:.4f}\")\n",
    "print(f\"Unweighted Uncentered Total Sum of Squares (TSS): {unweighted_uncentered_tss:.4f}\")\n",
    "\n",
    "# Explained Sum of Squares (ESS)\n",
    "ess_weighted = np.sum(weights * (y_pred - weighted_mean_y)**2)\n",
    "ess_unweighted = np.sum((y_pred - unweighted_mean_y)**2)\n",
    "print(f\"\\nWeighted Explained Sum of Squares (ESS): {ess_weighted:.4f}\")\n",
    "print(f\"Unweighted Explained Sum of Squares (ESS): {ess_unweighted:.4f}\")\n",
    "\n",
    "results['unweighted_centered_tss'] = unweighted_centered_tss\n",
    "results['weighted_centered_tss'] = weighted_centered_tss\n",
    "results['unweighted_uncentered_tss'] = unweighted_uncentered_tss\n",
    "results['weighted_uncentered_tss'] = weighted_uncentered_tss\n",
    "results['ess_weighted'] = ess_weighted\n",
    "results['ess_unweighted'] = ess_unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86f45e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Goodness-of-Fit ---\n",
      "\n",
      "Weighted R-squared: 0.9798\n",
      "Unweighted R-squared: 0.9798\n",
      "\n",
      "Weighted Adjusted R-squared: 0.9757\n",
      "Unweighted Adjusted R-squared: 0.9757\n",
      "\n",
      "Chi-Squared: 444.5407\n",
      "Reduced Chi-Squared (RSS_weighted / degrees_of_freedom): 88.9081\n"
     ]
    }
   ],
   "source": [
    "# --- Goodness-of-Fit Metrics ---\n",
    "print(\"\\n--- Goodness-of-Fit ---\")\n",
    "\n",
    "# R-squared\n",
    "r_squared_weighted = 1 - rss_weighted / weighted_centered_tss\n",
    "r_squared_unweighted = 1 - rss_unweighted / unweighted_centered_tss\n",
    "print(f\"\\nWeighted R-squared: {r_squared_weighted:.4f}\")\n",
    "print(f\"Unweighted R-squared: {r_squared_unweighted:.4f}\")\n",
    "\n",
    "# Adjusted R-squared\n",
    "r_squared_adj_weighted = 1 - (1 - r_squared_weighted) * ((n - 1) / (n - p))\n",
    "r_squared_adj_unweighted = 1 - (1 - r_squared_unweighted) * ((n - 1) / (n - p))\n",
    "print(f\"\\nWeighted Adjusted R-squared: {r_squared_adj_weighted:.4f}\")\n",
    "print(f\"Unweighted Adjusted R-squared: {r_squared_adj_unweighted:.4f}\")\n",
    "\n",
    "# Chi-Squared and Reduced Chi-Squared\n",
    "chi_squared = rss_weighted # By definition\n",
    "reduced_chi_squared = chi_squared / degrees_of_freedom\n",
    "print(f\"\\nChi-Squared: {chi_squared:.4f}\")\n",
    "print(f\"Reduced Chi-Squared (RSS_weighted / degrees_of_freedom): {reduced_chi_squared:.4f}\")\n",
    "\n",
    "results['r_squared_weighted'] = r_squared_weighted\n",
    "results['r_squared_unweighted'] = r_squared_unweighted\n",
    "results['r_squared_adj_weighted'] = r_squared_adj_weighted\n",
    "results['r_squared_adj_unweighted'] = r_squared_adj_unweighted\n",
    "results['chi_squared'] = chi_squared\n",
    "results['reduced_chi_squared'] = reduced_chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "240ab26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Error Metrics ---\n",
      "\n",
      "Unweighted RMSE: 3.9845\n",
      "Weighted RMSE: 3.9845\n",
      "\n",
      "Unweighted SER: 4.7146\n",
      "Weighted SER: 9.4291\n",
      "\n",
      "--- Mean Squared Errors (MSE) ---\n",
      "\n",
      "Weighted Mean Squared Error (MSE): 24295.5217\n",
      "Weighted MSE: 88.9081\n",
      "Weighted Total MSE: 3661.7333\n"
     ]
    }
   ],
   "source": [
    "# --- Error Metrics ---\n",
    "print(\"--- Error Metrics ---\")\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse_unweighted = np.sqrt(rss_unweighted / n)\n",
    "rmse_weighted = np.sqrt(rss_weighted / np.sum(weights))\n",
    "print(f\"\\nUnweighted RMSE: {rmse_unweighted:.4f}\")\n",
    "print(f\"Weighted RMSE: {rmse_weighted:.4f}\")\n",
    "\n",
    "# Standard Error of the Regression (SER)\n",
    "ser_unweighted = np.sqrt(rss_unweighted / degrees_of_freedom)\n",
    "ser_weighted = np.sqrt(rss_weighted / degrees_of_freedom) # Same as sqrt of reduced_chi_squared\n",
    "print(f\"\\nUnweighted SER: {ser_unweighted:.4f}\")\n",
    "print(f\"Weighted SER: {ser_weighted:.4f}\")\n",
    "\n",
    "# --- Mean Squared Errors (MSE) ---\n",
    "print(\"\\n--- Mean Squared Errors (MSE) ---\")\n",
    "mse_model_weighted = ess_weighted / (p - 1)\n",
    "mse_weighted = rss_weighted / (n - p) # Same as reduced chi-squared\n",
    "mse_total_weighted = weighted_centered_tss / (n - 1)\n",
    "print(f\"\\nWeighted Mean Squared Error (MSE): {mse_model_weighted:.4f}\")\n",
    "print(f\"Weighted MSE: {mse_weighted:.4f}\")\n",
    "print(f\"Weighted Total MSE: {mse_total_weighted:.4f}\")\n",
    "\n",
    "results['rmse_unweighted'] = rmse_unweighted\n",
    "results['rmse_weighted'] = rmse_weighted\n",
    "results['ser_unweighted'] = ser_unweighted\n",
    "results['ser_weighted'] = ser_weighted\n",
    "results['mse_model_weighted'] = mse_model_weighted\n",
    "results['mse_weighted'] = mse_weighted\n",
    "results['mse_total_weighted'] = mse_total_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8880a74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Log-Likelihood & Information Criteria ---\n",
      "MLE for variance (RSS_weighted / n): 63.5058\n",
      "Maximum Log-Likelihood: -19.6095\n",
      "AIC (Akaike Information Criterion): 43.2190\n",
      "BIC (Bayesian Information Criterion): 43.1108\n",
      "AICc (Corrected AIC): 46.2190\n"
     ]
    }
   ],
   "source": [
    "# --- Log-Likelihood and Information Criteria ---\n",
    "print(\"\\n--- Log-Likelihood & Information Criteria ---\")\n",
    "# Since absolute_sigma=False, we assume sigma is not known, but the weights are known.\n",
    "\n",
    "# First, calculate the Maximum Likelihood Estimate for the scale/variance parameter\n",
    "mle_variance = rss_weighted / n\n",
    "print(f\"MLE for variance (RSS_weighted / n): {mle_variance:.4f}\")\n",
    "\n",
    "term1 = -n / 2 * (np.log(2 * np.pi) + 1)\n",
    "term2 = -n / 2 * np.log(mle_variance)\n",
    "term3 = 0.5 * np.sum(np.log(weights))\n",
    "llf = term1 + term2 + term3\n",
    "print(f\"Maximum Log-Likelihood: {llf:.4f}\")\n",
    "\n",
    "# Information Criteria\n",
    "aic = -2 * llf + 2 * p\n",
    "bic = -2 * llf + np.log(n) * p\n",
    "aicc = aic + (2 * p * (p + 1)) / (n - p - 1)\n",
    "print(f\"AIC (Akaike Information Criterion): {aic:.4f}\")\n",
    "print(f\"BIC (Bayesian Information Criterion): {bic:.4f}\")\n",
    "print(f\"AICc (Corrected AIC): {aicc:.4f}\")\n",
    "\n",
    "results['mle_variance'] = mle_variance\n",
    "results['log_likelihood'] = llf\n",
    "results['aic'] = aic\n",
    "results['bic'] = bic\n",
    "results['aicc'] = aicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1541cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_data': array([ 0,  5, 25, 34, 42, 57, 97]),\n",
       " 'y_data': array([100. ,  79.7,  51.3,  44.6,  39.8,  29.9,  10.3]),\n",
       " 'sigma': array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       " 'weights': array([4., 4., 4., 4., 4., 4., 4.]),\n",
       " 'fit_a': np.float64(93.53552979274119),\n",
       " 'fit_b': np.float64(0.02697161541461497),\n",
       " 'std_err_a': np.float64(0.8080142341097194),\n",
       " 'std_err_b': np.float64(0.0005040716988170932),\n",
       " 'number_of_observations': 7,\n",
       " 'number_of_parameters': 2,\n",
       " 'degrees_of_freedom': 5,\n",
       " 'y_pred': array([100.        ,  88.19955015,  54.12249259,  43.85084912,\n",
       "         36.59483663,  26.56928409,  13.29973129]),\n",
       " 'residuals_calc': array([ 0.        , -8.49955015, -2.82249259,  0.74915088,  3.20516337,\n",
       "         3.33071591, -2.99973129]),\n",
       " 'weighted_residuals': array([  0.        , -16.99910031,  -5.64498518,   1.49830177,\n",
       "          6.41032674,   6.66143181,  -5.99946257]),\n",
       " 'residuals_scipy': array([ 0.        , 16.99910031,  5.64498518, -1.49830177, -6.41032674,\n",
       "        -6.66143181,  5.99946257]),\n",
       " 'condition_number': np.float64(17123879.749667574),\n",
       " 'rss_unweighted': np.float64(111.13517273880338),\n",
       " 'rss_weighted': np.float64(444.5406909552135),\n",
       " 'unweighted_centered_tss': np.float64(5492.6),\n",
       " 'weighted_centered_tss': np.float64(21970.4),\n",
       " 'unweighted_uncentered_tss': np.float64(23557.079999999998),\n",
       " 'weighted_uncentered_tss': np.float64(94228.31999999999),\n",
       " 'ess_weighted': np.float64(24295.521680193942),\n",
       " 'ess_unweighted': np.float64(6073.880420048486),\n",
       " 'r_squared_weighted': np.float64(0.9797663815426568),\n",
       " 'r_squared_unweighted': np.float64(0.9797663815426568),\n",
       " 'r_squared_adj_weighted': np.float64(0.9757196578511882),\n",
       " 'r_squared_adj_unweighted': np.float64(0.9757196578511882),\n",
       " 'chi_squared': np.float64(444.5406909552135),\n",
       " 'reduced_chi_squared': np.float64(88.9081381910427),\n",
       " 'rmse_unweighted': np.float64(3.984526728282856),\n",
       " 'rmse_weighted': np.float64(3.984526728282856),\n",
       " 'ser_unweighted': np.float64(4.714555604482852),\n",
       " 'ser_weighted': np.float64(9.429111208965704),\n",
       " 'mse_model_weighted': np.float64(24295.521680193942),\n",
       " 'mse_weighted': np.float64(88.9081381910427),\n",
       " 'mse_total_weighted': np.float64(3661.7333333333336),\n",
       " 'mle_variance': np.float64(63.50581299360193),\n",
       " 'log_likelihood': np.float64(-19.609499525716124),\n",
       " 'aic': np.float64(43.21899905143225),\n",
       " 'bic': np.float64(43.11081934954287),\n",
       " 'aicc': np.float64(46.21899905143225)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb04d79",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[32m      5\u001b[39m     plt.subplot(\u001b[38;5;28mlen\u001b[39m(results), \u001b[32m1\u001b[39m, i + \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     plt.scatter(\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, res[\u001b[33m\"\u001b[39m\u001b[33my_data\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mOriginal Data\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m, s=\u001b[32m50\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33my_predicted\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[32m      9\u001b[39m         x_plot = np.linspace(\u001b[38;5;28mmin\u001b[39m(res[\u001b[33m\"\u001b[39m\u001b[33mx_data\u001b[39m\u001b[33m\"\u001b[39m]), \u001b[38;5;28mmax\u001b[39m(res[\u001b[33m\"\u001b[39m\u001b[33mx_data\u001b[39m\u001b[33m\"\u001b[39m]), \u001b[32m500\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Plotting the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    plt.subplot(len(results), 1, i + 1)\n",
    "    plt.scatter(res[\"x_data\"], res[\"y_data\"], label=\"Original Data\", color='blue', s=50)\n",
    "\n",
    "    if \"y_predicted\" in res:\n",
    "        x_plot = np.linspace(min(res[\"x_data\"]), max(res[\"x_data\"]), 500)\n",
    "        y_plot = custom_function(x_plot, res[\"A_fit\"], res[\"B_fit\"])\n",
    "        plt.plot(x_plot, y_plot, color='red', label=f\"Fitted Curve\\nA={res['A_fit']:.2f}±{res['A_err']:.2f}\\nB={res['B_fit']:.4f}±{res['B_err']:.4f}\")\n",
    "\n",
    "        if not np.isnan(res['adjusted_r_squared']):\n",
    "            plt.title(f\"R²={res['r_squared']:.3f}, Adj. R²={res['adjusted_r_squared']:.3f}\\nRMSE={res['rmse']:.2f}, $\\\\chi^2={res['chi_squared']:.4f}$, $\\\\chi^2_{{red}}={res['reduced_chi_squared']:.4f}$\")\n",
    "        else:\n",
    "            plt.title(f\"R²={res['r_squared']:.3f}, RMSE={res['rmse']:.2f}\\nAdj. R²: N/A\")\n",
    "    else:\n",
    "        plt.title(f\"Fit (Error)\")\n",
    "        plt.text(0.5, 0.5, f\"Error: {res['error']}\", horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes, color='red')\n",
    "\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf25d51",
   "metadata": {},
   "source": [
    "### Analysis of the results\n",
    "\n",
    "The results are totally the same as in the previous case.\n",
    "\n",
    "It's clear that for dataset 1 and dataset 2 the results of our analysis show that the selected function doesn't fit the data well enough:\n",
    "* RMSE is too high\n",
    "* $\\chi^2_{red}$ is too high\n",
    "\n",
    "Thus, we need to look for another custom function for the datasets 1 and 2.\n",
    "\n",
    "For the dataset 3:\n",
    "\n",
    "* **Reduced Chi-Squared ($\\chi^2_{red}$):** This is a measure of the **goodness-of-fit relative to our assumed measurement errors**. It normalizes the residuals by the standard deviation of the measurements ($\\sigma_i$). A value close to 1 means the observed scatter of our data points around the fit is consistent with our assumed uncertainties.\n",
    "    * Since $\\chi^2_{red}$ is 1.4472 (greater than 1), it suggests that the scatter in our data is **larger than what we expected** based on our assumed standard deviation of 0.5. This implies that we have likely **underestimated the true measurement uncertainty**.\n",
    "\n",
    "* **Root Mean Squared Error (RMSE):** This is an **estimate of the standard deviation of the residuals**. The fact that our RMSE (0.5084) is very close to our assumed $\\sigma_i$ of 0.5 is a common occurrence and shows that our model is fitting the data well. However, because the reduced chi-squared is greater than 1, it tells us that the true underlying noise in the data is likely a bit larger than 0.5, even if the RMSE is close to that value. The $\\chi^2_{red}$ is a more robust statistical tool for validating our assumption about the uncertainty of our measurements.\n",
    "\n",
    "Let's try to increase the standard deviations from 0.5 to 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556344c",
   "metadata": {},
   "source": [
    "### Usage of the Higher Value of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b791f89",
   "metadata": {},
   "source": [
    "Results for the dataset 1 and 2:\n",
    "* RMSE is too high\n",
    "* $\\chi^2_{red}$ is too high\n",
    "\n",
    "Results for the dataset 3:\n",
    "* A reduced chi-squared value of 0.3618 is too low and indicates that we have overestimated the standard deviation of our measurements.\n",
    "* Also, note that the errors for A and B parameters were increased afrer we increased\n",
    "\n",
    "The standard deviation of 0.6 will make $\\chi^2_{red}$ very close to 1 for the dataset 3 (see below)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}