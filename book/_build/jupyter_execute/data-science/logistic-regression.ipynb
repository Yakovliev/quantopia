{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1996ef9",
   "metadata": {},
   "source": [
    "# Logistic Regression (preview)\n",
    "\n",
    "Logistic Regression is a powerful and widely used statistical method for binary classification problems. Despite its name, it's a classification algorithm, not a regression algorithm. It models the probability of a binary outcome (e.g., spam/not spam, disease/no disease) using a logistic function.\n",
    "\n",
    "## The Core Idea: Modeling Probability\n",
    "\n",
    "Imagine you want to predict whether an email is spam based on certain features like the number of suspicious words, sender's reputation, etc. Logistic Regression allows you to predict \"spam\" or \"not spam\" and to predict the *probability* that an email is spam, a value between 0 and 1. Based on this probability, you can then classify the email. For example, if the probability is greater than 0.5, you might classify it as spam.\n",
    "\n",
    "**Why Not Linear Regression?**\n",
    "\n",
    "You might wonder, why can't we just use linear regression for this? If we were to use linear regression, our output could be any real number, but probabilities must be between 0 and 1. A linear model could predict probabilities less than 0 or greater than 1, which is nonsensical for probabilities. This is where the logistic function comes into play.\n",
    "\n",
    "**The Sigmoid (Logistic) Function**\n",
    "\n",
    "The heart of Logistic Regression is the **sigmoid function**, also known as the **logistic function**. This function squashes any real-valued number into a range between 0 and 1, making it perfect for modeling probabilities.\n",
    "\n",
    "The sigmoid function is defined as:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "where:\n",
    "* $\\sigma(z)$ (sigma of z) is the output of the sigmoid function, a probability between 0 and 1.\n",
    "* $e$ is Euler's number (approximately 2.71828).\n",
    "* $z$ is the input to the function, which can be any real number.\n",
    "\n",
    "Let's look at the shape of the sigmoid function:\n",
    "\n",
    "* As $ z \\to \\infty $, $ e^{-z} \\to 0 $, so $\\sigma(z) \\to \\frac{1}{1+0} = 1$.\n",
    "* As $ z \\to -\\infty $, $ e^{-z} \\to \\infty $, so $\\sigma(z) \\to \\frac{1}{\\infty} = 0$.\n",
    "* When $ z = 0 $, $ e^{-z} = e^0 = 1 $, so $\\sigma(z) = \\frac{1}{1+1} = 0.5$.\n",
    "\n",
    "This S-shaped curve nicely maps any linear combination of features to a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ff256",
   "metadata": {},
   "source": [
    "## The Linear Part: The Log-Odds\n",
    "\n",
    "Before feeding into the sigmoid function, we create a linear combination of our input features, similar to linear regression. This linear combination is often referred to as the **log-odds** or **logit**.\n",
    "\n",
    "For a single feature $ x_1 $:\n",
    "\n",
    "$$z = \\beta_0 + \\beta_1 x_1$$\n",
    "\n",
    "For multiple features $ x_1, x_2, \\ldots, x_n $:\n",
    "\n",
    "$$z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$$\n",
    "\n",
    "In a more compact vector notation, where $\\mathbf{x}$ is a vector of features (including a bias term $x_0 = 1$) and $\\boldsymbol{\\beta}$ is a vector of coefficients:\n",
    "\n",
    "$$z = \\boldsymbol{\\beta}^T \\mathbf{x}$$\n",
    "\n",
    "Here:\n",
    "* $\\beta_0$ is the intercept (bias term).\n",
    "* $\\beta_1, \\ldots, \\beta_n$ are the coefficients (weights) associated with each feature. These are the parameters our model will learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f71c05",
   "metadata": {},
   "source": [
    "## The Logistic Regression Model Equation\n",
    "\n",
    "Combining the linear part with the sigmoid function, we get the core equation for Logistic Regression:\n",
    "\n",
    "$$P(Y=1|\\mathbf{x}) = \\sigma(\\boldsymbol{\\beta}^T \\mathbf{x}) = \\frac{1}{1 + e^{-(\\boldsymbol{\\beta}^T \\mathbf{x})}}$$\n",
    "\n",
    "Here, $P(Y=1|\\mathbf{x})$ represents the probability that the outcome $ Y $ is 1 (the positive class) given the input features $ \\mathbf{x} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628eeda",
   "metadata": {},
   "source": [
    "## Interpreting the Coefficients\n",
    "\n",
    "The coefficients $\\beta_i$ in Logistic Regression are not as straightforward to interpret as in linear regression. A positive $\\beta_i$ means that as $x_i$ increases, the probability of the positive class ($Y=1$) increases. Conversely, a negative $\\beta_i$ means that as $x_i$ increases, the probability of the positive class decreases.\n",
    "\n",
    "Specifically, $e^{\\beta_i}$ represents the odds ratio. For a one-unit increase in $ x_i $, the odds of $Y=1$ (versus $Y=0$) are multiplied by $ e^{\\beta_i} $, assuming all other features remain constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbe5df",
   "metadata": {},
   "source": [
    "## Decision Boundary\n",
    "\n",
    "Once we have the probabilities, we need a way to classify. We typically set a threshold (e.g., 0.5). If $ P(Y=1|\\mathbf{x}) \\geq 0.5 $, we classify as 1; otherwise, we classify as 0.\n",
    "\n",
    "The decision boundary is where the probability is 0.5. Since $\\sigma(z) = 0.5$ when $ z = 0 $, the decision boundary is defined by:\n",
    "\n",
    "$$\\boldsymbol{\\beta}^T \\mathbf{x} = 0$$\n",
    "\n",
    "This means that the decision boundary is a linear hyperplane in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c459b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7544e3",
   "metadata": {},
   "source": [
    "## Learning the Parameters: Maximum Likelihood Estimation\n",
    "\n",
    "How do we find the optimal values for $ \\boldsymbol{\\beta} $? We use a method called **Maximum Likelihood Estimation (MLE)**.\n",
    "\n",
    "Instead of minimizing squared errors (like in linear regression), we want to find the $\\boldsymbol{\\beta}$ values that maximize the likelihood of observing our training data. In other words, we want to choose $\\boldsymbol{\\beta}$ such that the predicted probabilities for the observed outcomes are as high as possible.\n",
    "\n",
    "Let's assume we have $m$ training examples $ (\\mathbf{x}^{(1)}, y^{(1)}), \\ldots, (\\mathbf{x}^{(m)}, y^{(m)}) $, where $y^{(i)} \\in \\{0, 1\\}$.\n",
    "\n",
    "The probability of observing a single training example $(\\mathbf{x}^{(i)}, y^{(i)})$ is:\n",
    "\n",
    "* If $ y^{(i)} = 1 $: $P(Y=1|\\mathbf{x}^{(i)}; \\boldsymbol{\\beta}) = h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})$\n",
    "* If $ y^{(i)} = 0 $: $P(Y=0|\\mathbf{x}^{(i)}; \\boldsymbol{\\beta}) = 1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})$\n",
    "\n",
    "We can combine these into a single expression:\n",
    "\n",
    "$$P(y^{(i)}|\\mathbf{x}^{(i)}; \\boldsymbol{\\beta}) = (h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}))^{y^{(i)}} (1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}))^{1 - y^{(i)}}$$\n",
    "\n",
    "Where $h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) = \\sigma(\\boldsymbol{\\beta}^T \\mathbf{x}^{(i)})$.\n",
    "\n",
    "The **likelihood function** $L(\\boldsymbol{\\beta})$ is the product of the probabilities of all training examples (assuming they are independent and identically distributed):\n",
    "\n",
    "$$L(\\boldsymbol{\\beta}) = \\prod_{i=1}^{m} (h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}))^{y^{(i)}} (1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}))^{1 - y^{(i)}}$$\n",
    "\n",
    "To simplify calculations, it's common to work with the **log-likelihood function**, as maximizing the likelihood is equivalent to maximizing the log-likelihood (due to the monotonic nature of the logarithm):\n",
    "\n",
    "$$\\text{log}L(\\boldsymbol{\\beta}) = \\sum_{i=1}^{m} [y^{(i)} \\text{log}(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})) + (1 - y^{(i)}) \\text{log}(1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}))]$$\n",
    "\n",
    "This log-likelihood function is also known as the **cross-entropy cost function** (or negative log-likelihood) for binary classification. We typically try to *minimize* the negative log-likelihood:\n",
    "\n",
    "$$J(\\boldsymbol{\\beta}) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\text{log}(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})) + (1 - y^{(i)}) \\text{log}(1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fbbd9",
   "metadata": {},
   "source": [
    "## Gradient Descent for Optimization\n",
    "\n",
    "To find the values of $\\boldsymbol{\\beta}$ that minimize $ J(\\boldsymbol{\\beta}) $, we use an iterative optimization algorithm like **Gradient Descent**.\n",
    "\n",
    "The update rule for each parameter $\\beta_j$ is:\n",
    "\n",
    "$$\\beta_j := \\beta_j - \\alpha \\frac{\\partial J(\\boldsymbol{\\beta})}{\\partial \\beta_j}$$\n",
    "\n",
    "Where $\\alpha$ is the learning rate.\n",
    "\n",
    "Let's derive the partial derivative $ \\frac{\\partial J(\\boldsymbol{\\beta})}{\\partial \\beta_j} $:\n",
    "\n",
    "First, recall $h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) = \\sigma(z^{(i)}) = \\frac{1}{1 + e^{-z^{(i)}}}$ where $z^{(i)} = \\boldsymbol{\\beta}^T \\mathbf{x}^{(i)}$.\n",
    "\n",
    "The derivative of the sigmoid function is quite elegant:\n",
    "$$\\frac{d\\sigma(z)}{dz} = \\sigma(z)(1 - \\sigma(z))$$\n",
    "\n",
    "Now, let's derive the derivative of a single term in the cost function with respect to $ \\beta_j $:\n",
    "\n",
    "Let $\\text{cost}^{(i)} = -[y^{(i)} \\text{log}(h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})) + (1 - y^{(i)}) \\text{log}(1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}))]$.\n",
    "\n",
    "$$\\frac{\\partial \\text{cost}^{(i)}}{\\partial \\beta_j} = - \\left[ \\frac{y^{(i)}}{h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})} \\frac{\\partial h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})}{\\partial \\beta_j} + \\frac{1 - y^{(i)}}{1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})} \\left( -\\frac{\\partial h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})}{\\partial \\beta_j} \\right) \\right]$$\n",
    "\n",
    "$$\\frac{\\partial \\text{cost}^{(i)}}{\\partial \\beta_j} = - \\left[ \\frac{y^{(i)}}{h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})} - \\frac{1 - y^{(i)}}{1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})} \\right] \\frac{\\partial h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})}{\\partial \\beta_j}$$\n",
    "\n",
    "We know $ \\frac{\\partial h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})}{\\partial \\beta_j} = \\frac{\\partial \\sigma(z^{(i)})}{\\partial z^{(i)}} \\frac{\\partial z^{(i)}}{\\partial \\beta_j} = \\sigma(z^{(i)})(1 - \\sigma(z^{(i)})) x_j^{(i)} = h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})(1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})) x_j^{(i)} $.\n",
    "\n",
    "Substitute this back:\n",
    "\n",
    "$$\\frac{\\partial \\text{cost}^{(i)}}{\\partial \\beta_j} = - \\left[ \\frac{y^{(i)}}{h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})} - \\frac{1 - y^{(i)}}{1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})} \\right] h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})(1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})) x_j^{(i)}$$\n",
    "\n",
    "$$\\frac{\\partial \\text{cost}^{(i)}}{\\partial \\beta_j} = - \\left[ y^{(i)}(1 - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)})) - (1 - y^{(i)})h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) \\right] x_j^{(i)}$$\n",
    "\n",
    "$$\\frac{\\partial \\text{cost}^{(i)}}{\\partial \\beta_j} = - \\left[ y^{(i)} - y^{(i)}h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) + y^{(i)}h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) \\right] x_j^{(i)}$$\n",
    "\n",
    "$$\\frac{\\partial \\text{cost}^{(i)}}{\\partial \\beta_j} = - \\left[ y^{(i)} - h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) \\right] x_j^{(i)}$$\n",
    "\n",
    "$$\\frac{\\partial \\text{cost}^{(i)}}{\\partial \\beta_j} = (h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)}$$\n",
    "\n",
    "So, the partial derivative of the total cost function $J(\\boldsymbol{\\beta})$ with respect to $\\beta_j$ is:\n",
    "\n",
    "$$\\frac{\\partial J(\\boldsymbol{\\beta})}{\\partial \\beta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)}$$\n",
    "\n",
    "This is remarkably similar to the gradient descent update rule for linear regression, which is a nice feature of using the sigmoid function and the cross-entropy loss.\n",
    "\n",
    "The gradient descent update rule becomes:\n",
    "\n",
    "$$\\beta_j := \\beta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\boldsymbol{\\beta}}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)}$$\n",
    "\n",
    "We repeatedly apply this update rule for all $\\beta_j$ (simultaneously) until convergence (i.e., the parameters stop changing significantly or the cost function converges).\n",
    "\n",
    "## Simple Examples\n",
    "\n",
    "Let's illustrate with some conceptual examples.\n",
    "\n",
    "### Example 1: Admitting to College\n",
    "\n",
    "Imagine we want to predict whether a student will be admitted to a prestigious college based on their SAT score.\n",
    "\n",
    "* **Input Feature (x):** SAT Score (e.g., 800 - 1600)\n",
    "* **Output (Y):** 1 (Admitted), 0 (Not Admitted)\n",
    "\n",
    "The Logistic Regression model would learn a relationship like this:\n",
    "\n",
    "$$P(\\text{Admitted}=1|\\text{SAT Score}) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 \\cdot \\text{SAT Score})}}$$\n",
    "\n",
    "Let's say after training, we find $\\beta_0 = -10$ and $\\beta_1 = 0.008$.\n",
    "\n",
    "* If a student has an SAT score of 1200:\n",
    "    $z = -10 + 0.008 \\cdot 1200 = -10 + 9.6 = -0.4$\n",
    "    $P(\\text{Admitted}=1|\\text{SAT}=1200) = \\frac{1}{1 + e^{-(-0.4)}} = \\frac{1}{1 + e^{0.4}} \\approx \\frac{1}{1 + 1.49} \\approx 0.40$\n",
    "    With a threshold of 0.5, this student would likely not be admitted.\n",
    "\n",
    "* If a student has an SAT score of 1400:\n",
    "    $z = -10 + 0.008 \\cdot 1400 = -10 + 11.2 = 1.2$\n",
    "    $P(\\text{Admitted}=1|\\text{SAT}=1400) = \\frac{1}{1 + e^{-(1.2)}} = \\frac{1}{1 + e^{-1.2}} \\approx \\frac{1}{1 + 0.30} \\approx 0.77$\n",
    "    With a threshold of 0.5, this student would likely be admitted.\n",
    "\n",
    "The model learns that higher SAT scores lead to a higher probability of admission. The $\\beta_1 = 0.008$ signifies that for every one-point increase in SAT score, the log-odds of admission increase by 0.008.\n",
    "\n",
    "### Example 2: Detecting Spam Email\n",
    "\n",
    "Let's say we have two features:\n",
    "\n",
    "* **x1:** Number of suspicious words (e.g., \"win,\" \"prize,\" \"free\")\n",
    "* **x2:** Sender's reputation score (e.g., 0-10, lower is worse)\n",
    "* **Y:** 1 (Spam), 0 (Not Spam)\n",
    "\n",
    "Our model would be:\n",
    "\n",
    "$$P(\\text{Spam}=1|x_1, x_2) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)}}$$\n",
    "\n",
    "Suppose after training, $ \\beta_0 = -2 $, $ \\beta_1 = 0.5 $, and $\\beta_2 = -0.3$.\n",
    "\n",
    "* **Email A:** 5 suspicious words ($x_1=5$), sender reputation 8 ($x_2=8$)\n",
    "    $z = -2 + (0.5 \\cdot 5) + (-0.3 \\cdot 8) = -2 + 2.5 - 2.4 = -1.9$\n",
    "    $P(\\text{Spam}=1|\\text{Email A}) = \\frac{1}{1 + e^{-(-1.9)}} = \\frac{1}{1 + e^{1.9}} \\approx \\frac{1}{1 + 6.68} \\approx 0.13$\n",
    "    Likely not spam.\n",
    "\n",
    "* **Email B:** 10 suspicious words ($x_1=10$), sender reputation 2 ($x_2=2$)\n",
    "    $z = -2 + (0.5 \\cdot 10) + (-0.3 \\cdot 2) = -2 + 5 - 0.6 = 2.4$\n",
    "    $P(\\text{Spam}=1|\\text{Email B}) = \\frac{1}{1 + e^{-(2.4)}} = \\frac{1}{1 + e^{-2.4}} \\approx \\frac{1}{1 + 0.09} \\approx 0.91$\n",
    "    Likely spam.\n",
    "\n",
    "Here, a positive $\\beta_1$ means more suspicious words increase the probability of spam, and a negative $\\beta_2$ means a lower sender reputation (lower $x_2$) increases the probability of spam.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Logistic Regression is a fundamental machine learning algorithm for binary classification. It leverages the sigmoid function to map linear combinations of features to probabilities, which are then used for classification. Maximum Likelihood Estimation, typically optimized via Gradient Descent, is used to learn the model's parameters. Its interpretability and simplicity make it a popular choice for many real-world classification problems.\n",
    "\n",
    "Let me know if you'd like to delve into more advanced topics like regularization, multiclass logistic regression, or practical implementation details!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2df571",
   "metadata": {},
   "source": [
    "## Additional Materials\n",
    "\n",
    "* https://www.ibm.com/think/topics/logistic-regression\n",
    "* https://developers.google.com/machine-learning/crash-course/logistic-regression/sigmoid-function?hl=en\n",
    "* https://www.v7labs.com/blog/logistic-regression\n",
    "* https://www.geeksforgeeks.org/understanding-logistic-regression/\n",
    "* https://www.geeksforgeeks.org/gradient-descent-algorithm-and-its-variants/\n",
    "* https://en.wikipedia.org/wiki/Gradient_descent\n",
    "* https://en.wikipedia.org/wiki/Cross-entropy\n",
    "* https://www.kellerbiostat.com/introregression/logisticinference\n",
    "* https://www.datacamp.com/tutorial/understanding-logistic-regression-python\n",
    "* https://ai-ml-analytics.com/logistic-regression-practical-example\n",
    "* https://www.simplilearn.com/tutorials/machine-learning-tutorial/logistic-regression-in-python\n",
    "* https://en.wikipedia.org/wiki/Sigmoid_function"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}