{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5081d360",
   "metadata": {},
   "source": [
    "\n",
    "### 1. The Nature of Measurement in Physics\n",
    "\n",
    "In physics, a **measurement** is the process of quantitatively determining a physical property of an object or phenomenon. We might measure the length of a pendulum, the temperature of a liquid, or the time it takes for a ball to fall. These are called **direct measurements**, as we read the value straight from a measuring instrument.\n",
    "\n",
    "Often, however, we need to determine a quantity that cannot be measured directly. For example, to find the density of a cube, we would measure its mass and the length of its side directly, and then calculate the density. This is an **indirect measurement**.\n",
    "\n",
    "A crucial concept we must accept is that no measurement is perfect. Every measurement is subject to some level of uncertainty. Our goal is not just to get a number, but to state with a certain level of confidence how close our measured value is likely to be to the true, unknown value. This is where the analysis of measurement errors comes in.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Understanding Measurement Errors\n",
    "\n",
    "The overall uncertainty in a measurement is called an error. We can classify measurement errors into three main categories.\n",
    "\n",
    "#### 2.1. Systematic Errors\n",
    "\n",
    "Systematic errors are inaccuracies that are consistently in the same direction; they cause your measured value to be consistently higher or lower than the true value. Imagine trying to measure the length of a table with a metal ruler that has expanded on a hot day. Every measurement you take will be slightly shorter than the real length.\n",
    "\n",
    "Sources of systematic errors include:\n",
    "*   **Instrumental errors:** These arise from imperfections or faulty calibration of the instrument, like a worn-out end of a meter stick or a miscalibrated digital scale.\n",
    "*   **Personal errors:** These can occur due to an observer's bias or consistent parallax error when reading a scale.\n",
    "*   **Imperfections in technique:** For instance, not accounting for heat loss in a calorimetry experiment would lead to a systematic error.\n",
    "*   **External causes:** Changes in environmental conditions like temperature, pressure, or humidity can systematically affect the measurement.\n",
    "\n",
    "Systematic errors are difficult to detect through statistical analysis alone. They can be minimized by carefully calibrating instruments and refining experimental techniques.\n",
    "\n",
    "#### 2.2. Random Errors\n",
    "\n",
    "Random errors are unpredictable fluctuations in measurements. If you measure the same quantity multiple times, you will likely get slightly different readings each time. These variations can be caused by unpredictable changes in experimental conditions (like minor temperature fluctuations or air currents) or by the limitations of the observer's senses when estimating a reading between the marks on a scale.\n",
    "\n",
    "Unlike systematic errors, random errors can be analyzed statistically and their effect can be reduced by repeating the measurement many times and calculating the average.\n",
    "\n",
    "#### 2.3. Gross Errors (Blunders)\n",
    "\n",
    "Gross errors are mistakes or blunders made by the experimenter. Examples include misreading the scale (reading 3.5 cm as 8.5 cm), recording the wrong value, or making a calculation mistake. These errors are typically large and can be identified by looking for data points that are significant outliers. We can usually avoid these errors by being careful and vigilant during the experiment.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Statistical Processing of Direct Measurements\n",
    "\n",
    "When we have a set of `n` direct measurements of a quantity `x`, say $\\{x_1, x_2, \\dots, x_n\\}$, our goal is to find the best estimate for the true value and quantify the uncertainty associated with this estimate.\n",
    "\n",
    "#### 3.1. The Best Estimate: Arithmetic Mean\n",
    "\n",
    "The most common and best estimate for the true value of the measured quantity is the **arithmetic mean**, often denoted as $\\bar{x}$.\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "The logic is that random errors are just as likely to be positive as they are to be negative, so by averaging a large number of measurements, these errors tend to cancel each other out.\n",
    "\n",
    "#### 3.2. Quantifying the Spread: Standard Deviation\n",
    "\n",
    "To describe the dispersion or scatter of our measurements around the mean, we use the **sample standard deviation**, `s_x`. It essentially represents the average amount of variability in the dataset. A small standard deviation indicates that the measurements are clustered closely around the mean.\n",
    "\n",
    "$$\n",
    "s_x = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "**Why `n-1`?** The use of `n-1` instead of `n` in the denominator might seem strange. This is because we are using the *sample mean* $\\bar{x}$ to calculate the deviations, which is itself an estimate of the true (but unknown) population mean. Using `n-1` corrects for the fact that the sample mean is always closer to the data points than the true mean, making the standard deviation a more accurate (unbiased) estimate of the true population standard deviation.\n",
    "\n",
    "The standard deviation, `s_x`, represents the uncertainty of a *single* measurement. It tells us that if we were to take one more measurement, we can be about 68% confident that it would fall within the range of $\\bar{x} \\pm s_x$.\n",
    "\n",
    "#### 3.3. Uncertainty of the Mean: Standard Error\n",
    "\n",
    "More often than not, we are interested in the uncertainty of our best estimate, the arithmetic mean, not a single measurement. This is given by the **standard error of the mean** (or simply standard error), $\\sigma_{\\bar{x}}$.\n",
    "\n",
    "$$\n",
    "\\sigma_{\\bar{x}} = \\frac{s_x}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "The standard error is always smaller than the standard deviation, which makes sense: our confidence in the average value increases as we take more measurements.\n",
    "\n",
    "**Derivation of the Standard Error of the Mean**\n",
    "\n",
    "We can derive this important formula from the properties of variance. Let's consider our sample mean $\\bar{x} = \\frac{1}{n}(x_1 + x_2 + \\dots + x_n)$. We want to find its variance, $\\text{Var}(\\bar{x})$.\n",
    "\n",
    "1.  Using the property that for a constant `c`, $\\text{Var}(c X) = c^2 \\text{Var}(X)$, we have:\n",
    "    $$\n",
    "    \\text{Var}(\\bar{x}) = \\text{Var}\\left(\\frac{1}{n}\\sum_{i=1}^{n} x_i\\right) = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^{n} x_i\\right)\n",
    "    $$\n",
    "2.  If the measurements $x_i$ are independent (which they should be), the variance of their sum is the sum of their variances:\n",
    "    $$\n",
    "    \\text{Var}(\\bar{x}) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\text{Var}(x_i)\n",
    "    $$\n",
    "3.  Each measurement $x_i$ is drawn from the same underlying distribution, so they all have the same variance, which we estimate with the square of the sample standard deviation, $s_x^2$.\n",
    "    $$\n",
    "    \\text{Var}(\\bar{x}) = \\frac{1}{n^2} \\sum_{i=1}^{n} s_x^2 = \\frac{1}{n^2} (n s_x^2) = \\frac{s_x^2}{n}\n",
    "    $$\n",
    "4.  The standard error is the standard deviation of the mean, which is the square root of its variance.\n",
    "    $$\n",
    "    \\sigma_{\\bar{x}} = \\sqrt{\\text{Var}(\\bar{x})} = \\sqrt{\\frac{s_x^2}{n}} = \\frac{s_x}{\\sqrt{n}}\n",
    "    $$\n",
    "\n",
    "#### 3.4. Confidence Intervals and the Student's t-distribution\n",
    "\n",
    "The standard error $\\sigma_{\\bar{x}}$ gives us a 68% confidence interval. This means there is a 68% probability that the true value lies within the range $\\bar{x} \\pm \\sigma_{\\bar{x}}$. In many scientific fields, however, a higher level of confidence is required, typically 95%.\n",
    "\n",
    "For small sample sizes (common in a lab setting), the distribution of the sample means doesn't perfectly follow a normal (Gaussian) distribution. Instead, it follows a **Student's t-distribution**. This distribution is similar to a normal distribution but is wider, with heavier tails, to account for the additional uncertainty when the sample size is small.\n",
    "\n",
    "To calculate the uncertainty, which we call the **confidence interval** $\\Delta x$, for a desired confidence probability (e.g., 95%), we multiply the standard error by the appropriate **Student's coefficient** $t_{\\alpha, n-1}$.\n",
    "\n",
    "$$\n",
    "\\Delta x = t_{\\alpha, n-1} \\cdot \\sigma_{\\bar{x}} = t_{\\alpha, n-1} \\cdot \\frac{s_x}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "The Student's coefficient depends on:\n",
    "*   The desired **confidence probability** $\\alpha$ (e.g., 0.95 for 95% confidence).\n",
    "*   The **degrees of freedom**, which for this case is `n-1`.\n",
    "\n",
    "We can find the value of $t_{\\alpha, n-1}$ from standard tables or using statistical software.\n",
    "\n",
    "#### 3.5. Expressing the Final Result\n",
    "\n",
    "The final result of a series of direct measurements is reported in the form:\n",
    "\n",
    "$$\n",
    "x = \\bar{x} \\pm \\Delta x\n",
    "$$\n",
    "\n",
    "The units of measurement must also be included. For instance, we might report the length of a rod as $L = (95.4 \\pm 0.2) \\text{ cm}$.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Analysis of Indirect Measurements (Propagation of Uncertainty)\n",
    "\n",
    "Most of the time, we calculate a quantity `F` based on several directly measured values, say `x, y, z, ...`. We need a way to determine the uncertainty in `F` based on the uncertainties in `x, y, z, ...`. This is called the **propagation of uncertainty**.\n",
    "\n",
    "The general method uses the concept of the **total differential** from calculus. If `F` is a function of several variables `F(x, y, ...)` the total differential `dF` describes how `F` changes when its variables change by small amounts `dx, dy, ...`.\n",
    "\n",
    "$$\n",
    "dF = \\frac{\\partial F}{\\partial x} dx + \\frac{\\partial F}{\\partial y} dy + \\dots\n",
    "$$\n",
    "\n",
    "Here, $\\frac{\\partial F}{\\partial x}$ is the **partial derivative** of `F` with respect to `x`. It tells us how sensitive `F` is to changes in `x` while holding the other variables constant.\n",
    "\n",
    "Assuming the errors in the measured variables are independent and random, we can derive the formula for the **standard error of the indirect measurement result**, $\\sigma_F$. We add the individual error contributions in *quadrature* (sum of squares):\n",
    "\n",
    "$$\n",
    "\\sigma_F = \\sqrt{ \\left( \\frac{\\partial F}{\\partial x} \\sigma_x \\right)^2 + \\left( \\frac{\\partial F}{\\partial y} \\sigma_y \\right)^2 + \\dots }\n",
    "$$\n",
    "\n",
    "where $\\sigma_x$, $\\sigma_y$, etc., are the standard errors (or uncertainties) of the directly measured quantities `x` and `y`.\n",
    "\n",
    "#### 4.1. Common Cases for Error Propagation\n",
    "\n",
    "Let's look at how this general formula applies to some common situations.\n",
    "\n",
    "*   **Addition and Subtraction:** If $F = x \\pm y$\n",
    "    $$\n",
    "    \\sigma_F = \\sqrt{\\sigma_x^2 + \\sigma_y^2}\n",
    "    $$\n",
    "    *Note: The uncertainties are always added in quadrature, even when subtracting the quantities.*\n",
    "\n",
    "*   **Multiplication and Division:** If $F = x \\cdot y$ or $F = x/y$\n",
    "    $$\n",
    "    \\frac{\\sigma_F}{F} = \\sqrt{ \\left(\\frac{\\sigma_x}{x}\\right)^2 + \\left(\\frac{\\sigma_y}{y}\\right)^2 }\n",
    "    $$\n",
    "    *Here, we work with relative uncertainties.*\n",
    "\n",
    "*   **Multiplication by a Constant:** If $F = c \\cdot x$, where `c` is a constant with no uncertainty.\n",
    "    $$\n",
    "    \\sigma_F = |c| \\sigma_x\n",
    "    $$\n",
    "\n",
    "*   **Raising to a Power:** If $F = x^m$, where `m` is a constant with no uncertainty.\n",
    "    $$\n",
    "    \\frac{\\sigma_F}{F} = |m| \\frac{\\sigma_x}{x}\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Reporting Final Results\n",
    "\n",
    "How we present our final result is just as important as how we calculate it.\n",
    "\n",
    "#### 5.1. Absolute and Relative Error\n",
    "\n",
    "The uncertainty $\\Delta x$ is the **absolute error**. It has the same units as the measured quantity.\n",
    "The **relative measurement error** (or fractional error) is the ratio of the absolute error to the best estimate of the value. It is often expressed as a percentage.\n",
    "\n",
    "$$\n",
    "\\text{Relative Error} = \\frac{\\Delta x}{\\bar{x}} \\quad (\\text{or } \\frac{\\Delta x}{\\bar{x}} \\times 100\\%)\n",
    "$$\n",
    "\n",
    "Relative error is useful for comparing the quality of different measurements. A measurement of the width of a room to within 1 cm is much better than a measurement of the width of a book to within 1 cm.\n",
    "\n",
    "#### 5.2. Rounding Rules and Significant Digits\n",
    "\n",
    "The number of digits we use to report a result should reflect its uncertainty. It's dishonest to report a result with more precision than is justified by the measurement.\n",
    "\n",
    "Here are the standard rules for rounding:\n",
    "\n",
    "1.  **Calculate the uncertainty first:** The uncertainty, $\\Delta x$, should almost always be rounded to one, or at most two, significant digits.\n",
    "2.  **Round the best estimate:** Round the mean value, $\\bar{x}$, to the same decimal place as the rounded uncertainty.\n",
    "\n",
    "For example, if we calculate a mean value of $\\bar{x} = 12.74825$ cm and an uncertainty of $\\Delta x = 0.03816$ cm:\n",
    "1.  Round the uncertainty to one significant digit: $\\Delta x \\approx 0.04$ cm.\n",
    "2.  Round the mean to the same decimal place (the hundredths place): $\\bar{x} \\approx 12.75$ cm.\n",
    "3.  The final result is reported as $(12.75 \\pm 0.04)$ cm.\n",
    "\n",
    "**Significant digits** (or significant figures) are the digits in a number that are known with some reliability. Non-zero digits are always significant. Zeros can be tricky:\n",
    "*   Zeros between non-zero digits are significant (e.g., 205 has three significant figures).\n",
    "*   Leading zeros are not significant (e.g., 0.054 has two significant figures).\n",
    "*   Trailing zeros after a decimal point are significant (e.g., 2.500 has four significant figures).\n",
    "\n",
    "When performing calculations, the number of significant figures in the result is limited by the least precise number used.\n",
    "*   For **multiplication and division**, the result should have the same number of significant figures as the input value with the fewest significant figures.\n",
    "*   For **addition and subtraction**, the result should have the same number of decimal places as the input value with the fewest decimal places.\n",
    "\n",
    "By carefully following these steps, we can process our experimental data, quantify its uncertainty, and report our findings in a clear, professional, and scientifically honest manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df142d",
   "metadata": {},
   "source": [
    "\n",
    "### 1. The Fundamentals of Measurement in Physics\n",
    "\n",
    "At its heart, physics is an experimental science. We develop theories to describe the universe, but these theories are only as good as the experimental evidence that supports them. This is where measurement comes in.\n",
    "\n",
    "A **measurement** is the process of quantitatively determining the value of a physical quantity. We do this by comparing the quantity to a standard unit. For example, when we measure the length of a table, we are comparing its length to a standard unit, the meter.\n",
    "\n",
    "The physical quantities we measure can be broadly categorized based on how we obtain their values:\n",
    "\n",
    "*   **Direct Measurements**: These are measurements where we obtain the value of a quantity directly by comparing it to a standard using a measuring instrument. For instance, measuring the length of a rod with a meter stick, the mass of an object with a balance, or the time interval with a stopwatch are all direct measurements. The value is read directly from the instrument's scale.\n",
    "*   **Indirect Measurements**: These are measurements of a quantity that is not measured directly. Instead, it is calculated from a mathematical relationship involving one or more directly measured quantities. For example, if we want to determine the area of a rectangular table, we would directly measure its length and width and then calculate the area using the formula `Area = Length × Width`. Similarly, determining the density of an object involves directly measuring its mass and volume and then calculating the density.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Understanding Measurement Errors\n",
    "\n",
    "No measurement is ever perfectly exact. Every measurement, no matter how carefully made, has an associated uncertainty, which we often call an **error**. This doesn't mean we made a mistake; it's an inherent part of the measurement process. The difference between the measured value and the true value of a quantity is called the measurement error. We can classify these errors into three main types.\n",
    "\n",
    "#### 2.1 Systematic Errors\n",
    "\n",
    "**Systematic errors** are those that consistently affect the measurement in the same direction—either always higher or always lower than the true value. These errors are reproducible if the measurement is repeated under the same conditions.\n",
    "\n",
    "**Sources of Systematic Errors:**\n",
    "\n",
    "*   **Instrumental Errors**: These arise from imperfections or faults in the measuring device. For example, a poorly calibrated thermometer might consistently read 2°C higher than the actual temperature, or a voltmeter might have a zero error, meaning it doesn't read zero when there's no voltage.\n",
    "*   **Environmental Errors**: These are caused by external conditions affecting the measurement. For instance, changes in temperature or pressure can affect the length of a metal rod or the resistance of a circuit.\n",
    "*   **Methodological Errors**: These stem from the experimental technique itself. An example is measuring the temperature of a human body with a thermometer placed under the armpit, which will consistently give a reading lower than the actual core body temperature.\n",
    "*   **Personal Errors**: These are due to the observer's bias. A common example is parallax error, which occurs when an observer consistently reads a scale from an angle instead of directly from the front.\n",
    "\n",
    "Systematic errors are particularly tricky because they cannot be reduced by simply repeating the measurement multiple times. To minimize them, we need to carefully calibrate our instruments, control the experimental environment, and refine our measurement techniques.\n",
    "\n",
    "#### 2.2 Random Errors\n",
    "\n",
    "**Random errors** are unpredictable fluctuations in the measured data. They can cause the result to be either higher or lower than the true value and vary with each measurement.\n",
    "\n",
    "**Sources of Random Errors:**\n",
    "\n",
    "*   Fluctuations in experimental conditions, such as slight variations in temperature or voltage.\n",
    "*   Limitations of the observer, like variations in reaction time when starting and stopping a stopwatch.\n",
    "*   Inherent randomness in the phenomenon being measured, such as the radioactive decay of atomic nuclei.\n",
    "\n",
    "Unlike systematic errors, random errors can be analyzed statistically. By taking a large number of measurements, we can reduce the effect of random errors on our final result.\n",
    "\n",
    "#### 2.3 Gross Errors (Blunders)\n",
    "\n",
    "**Gross errors**, or blunders, are mistakes made by the experimenter. These can be due to carelessness, such as misreading an instrument, recording the wrong value, or making a calculation error. When a data point is clearly the result of a gross error, it should be identified and discarded from the data set.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Statistical Processing of Direct Measurements\n",
    "\n",
    "To minimize the impact of random errors and obtain the most reliable estimate of a measured quantity, we typically perform a series of *n* independent measurements under the same conditions. Let's say we have a set of measurements $x_1, x_2, \\dots, x_n$.\n",
    "\n",
    "#### 3.1 The Arithmetic Mean: Our Best Estimate\n",
    "\n",
    "The single best estimate of the true value of the measured quantity is the **arithmetic mean** of our measurements.\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "The unit of the arithmetic mean is the same as the unit of the individual measurements.\n",
    "\n",
    "#### 3.2 Standard Error of a Single Measurement\n",
    "\n",
    "To quantify the spread or dispersion of our measurements due to random errors, we use the **sample standard deviation** $s_x$. This gives us an idea of the uncertainty of a single measurement.\n",
    "\n",
    "$$\n",
    "s_x = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "The term $n-1$ in the denominator is known as the number of degrees of freedom. The unit of the standard deviation is also the same as the unit of the measured quantity.\n",
    "\n",
    "#### 3.3 Standard Error of the Mean\n",
    "\n",
    "The arithmetic mean is a more reliable estimate of the true value than any single measurement. The uncertainty associated with the mean is given by the **standard error of the mean** $s_{\\bar{x}}$, which is smaller than the standard deviation of a single measurement by a factor of $\\sqrt{n}$.\n",
    "\n",
    "$$\n",
    "s_{\\bar{x}} = \\frac{s_x}{\\sqrt{n}} = \\sqrt{\\frac{1}{n(n-1)} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "**Derivation of the Standard Error of the Mean:**\n",
    "Let's consider the variance of the mean, which is the square of the standard error. The mean is calculated as $\\bar{x} = \\frac{1}{n}(x_1 + x_2 + \\dots + x_n)$. If the measurements $x_i$ are independent, the variance of their sum is the sum of their individual variances. Assuming each measurement comes from a distribution with variance $\\sigma^2$, the variance of the sum is $n\\sigma^2$. The variance of the mean is then:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\bar{x}) = \\text{Var}\\left(\\frac{1}{n}\\sum x_i\\right) = \\frac{1}{n^2} \\text{Var}\\left(\\sum x_i\\right) = \\frac{1}{n^2} (n\\sigma^2) = \\frac{\\sigma^2}{n}\n",
    "$$\n",
    "\n",
    "Taking the square root gives the standard deviation of the mean, $\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}$. In practice, we use the sample standard deviation $s_x$ as an estimate for $\\sigma$, leading to the formula for the standard error of the mean. This derivation shows that as we increase the number of measurements *n*, the uncertainty in our mean value decreases, making our result more precise.\n",
    "\n",
    "#### 3.4 The Confidence Interval and Student's Coefficient\n",
    "\n",
    "Our final result is not a single number but an interval within which the true value is likely to lie, with a certain level of confidence. This is called the **confidence interval**. The **confidence probability** $\\alpha$ (or reliability coefficient) is the probability that the true value lies within this interval. In student laboratories, a confidence probability of 95% ($\\alpha = 0.95$) is commonly used.\n",
    "\n",
    "For a small number of measurements (typical in a lab setting), the distribution of the mean follows a **Student's t-distribution** rather than a normal (Gaussian) distribution. To calculate the confidence interval, we use the **Student coefficient** $t_{\\alpha,n}$. This coefficient depends on the desired confidence probability $\\alpha$ and the number of measurements *n* (specifically, the degrees of freedom, $n-1$). The values of $t_{\\alpha,n}$ are found in standard statistical tables.\n",
    "\n",
    "The random error (or margin of error) $\\Delta x$ is then calculated as:\n",
    "\n",
    "$$\n",
    "\\Delta x = t_{\\alpha,n} \\cdot s_{\\bar{x}}\n",
    "$$\n",
    "\n",
    "The final result of our direct measurement is then presented in the form:\n",
    "\n",
    "$$\n",
    "X = \\bar{x} \\pm \\Delta x\n",
    "$$\n",
    "\n",
    "This means we are confident, with a probability of $\\alpha$, that the true value of the quantity *X* lies within the interval $[\\bar{x} - \\Delta x, \\bar{x} + \\Delta x]$.\n",
    "\n",
    "#### 3.5 Relative Measurement Error\n",
    "\n",
    "It is often useful to express the uncertainty in relation to the measured value. The **relative measurement error** $\\epsilon$ is the ratio of the absolute error to the mean value, usually expressed as a percentage.\n",
    "\n",
    "$$\n",
    "\\epsilon = \\frac{\\Delta x}{|\\bar{x}|} \\times 100\\%\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Processing Results of Indirect Measurements\n",
    "\n",
    "Many quantities in physics cannot be measured directly but are calculated from other directly measured quantities. For example, if a quantity *y* is a function of several directly measured quantities $x_1, x_2, \\dots, x_m$, we write $y = f(x_1, x_2, \\dots, x_m)$. The uncertainties in the direct measurements will propagate to the calculated value of *y*.\n",
    "\n",
    "#### 4.1 Derivation of the Standard Error for Indirect Measurements\n",
    "\n",
    "To find the uncertainty in *y*, we use a method based on the **total differential** of the function *f*. The total differential gives an approximation of the change in *y* for small changes in the independent variables:\n",
    "\n",
    "$$\n",
    "dy \\approx \\frac{\\partial f}{\\partial x_1} dx_1 + \\frac{\\partial f}{\\partial x_2} dx_2 + \\dots + \\frac{\\partial f}{\\partial x_m} dx_m\n",
    "$$\n",
    "\n",
    "Here, $\\frac{\\partial f}{\\partial x_i}$ is the **partial derivative** of *f* with respect to $x_i$. We can relate the small changes $dx_i$ to the standard errors of the direct measurements, $s_{x_i}$. Assuming the errors in the direct measurements are random and independent, the square of the standard error of the indirect measurement, $s_y^2$, is given by the sum of the squares of the individual error contributions:\n",
    "\n",
    "$$\n",
    "s_y^2 \\approx \\left(\\frac{\\partial f}{\\partial x_1} s_{x_1}\\right)^2 + \\left(\\frac{\\partial f}{\\partial x_2} s_{x_2}\\right)^2 + \\dots + \\left(\\frac{\\partial f}{\\partial x_m} s_{x_m}\\right)^2\n",
    "$$\n",
    "\n",
    "This leads to the formula for the **standard error of the indirect measurement result**:\n",
    "\n",
    "$$\n",
    "s_y = \\sqrt{\\sum_{i=1}^{m} \\left(\\frac{\\partial f}{\\partial x_i} s_{x_i}\\right)^2}\n",
    "$$\n",
    "\n",
    "To find the total uncertainty $\\Delta y$ for a certain confidence level, we replace the standard errors $s_{x_i}$ with their corresponding absolute uncertainties $\\Delta x_i$:\n",
    "\n",
    "$$\n",
    "\\Delta y = \\sqrt{\\sum_{i=1}^{m} \\left(\\frac{\\partial f}{\\partial x_i} \\Delta x_i\\right)^2}\n",
    "$$\n",
    "\n",
    "The best estimate for the value of *y* is found by substituting the arithmetic means of the directly measured quantities into the function: $\\bar{y} = f(\\bar{x}_1, \\bar{x}_2, \\dots, \\bar{x}_m)$.\n",
    "\n",
    "The final result for the indirect measurement is then reported as:\n",
    "\n",
    "$$\n",
    "Y = \\bar{y} \\pm \\Delta y\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Rounding Rules and Significant Digits\n",
    "\n",
    "The number of digits we use to report a result should reflect its precision. Using too many digits is misleading and scientifically meaningless. This is where **significant digits** and rounding rules are crucial.\n",
    "\n",
    "#### 5.1 Rules for Rounding\n",
    "\n",
    "1.  **Rounding the Uncertainty**: The calculated absolute uncertainty ($\\Delta x$ or $\\Delta y$) should almost always be rounded to one significant digit. If the leading digit of the uncertainty is a 1, it is acceptable to keep two significant digits.\n",
    "2.  **Rounding the Mean Value**: The mean value ($\\bar{x}$ or $\\bar{y}$) should be rounded to the same decimal place as the rounded uncertainty.\n",
    "\n",
    "**Example:**\n",
    "Suppose we calculate a mean value of $\\bar{l} = 9.87345$ m and an uncertainty of $\\Delta l = 0.04281$ m.\n",
    "\n",
    "*   First, round the uncertainty. The leading digit is 4, so we round to one significant digit: $\\Delta l = 0.04$ m.\n",
    "*   Next, round the mean value to the same decimal place as the uncertainty (the hundredths place): $\\bar{l} = 9.87$ m.\n",
    "*   The correctly reported result is $L = 9.87 \\pm 0.04$ m.\n",
    "\n",
    "By following these procedures, we can confidently and professionally analyze and report the results of our laboratory measurements, providing a clear and honest account of our findings and their inherent uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461f278",
   "metadata": {},
   "source": [
    "### 1. Main Topic of the Material\n",
    "\n",
    "The main topic is the **statistical analysis of measurement errors** in a physics laboratory setting. This includes understanding the types of errors, and the methods for processing results from both direct and indirect measurements to determine their uncertainty.\n",
    "\n",
    "### 2. Keywords and Formulas\n",
    "\n",
    "**Keywords from the provided material:**\n",
    "\n",
    "*   Measurement\n",
    "*   Direct measurements\n",
    "*   Indirect measurements\n",
    "*   Measurement error\n",
    "*   Systematic errors\n",
    "*   Random errors\n",
    "*   Gross errors (blunders)\n",
    "*   Statistical processing\n",
    "*   Arithmetic mean\n",
    "*   Confidence probability (reliability coefficient)\n",
    "*   Confidence interval\n",
    "*   Standard error of a single measurement\n",
    "*   Student coefficient\n",
    "*   Relative measurement error\n",
    "*   Total differential\n",
    "*   Partial derivatives\n",
    "*   Standard error of the indirect measurement result\n",
    "*   Rounding rules\n",
    "*   Significant digits\n",
    "*   $x_{avg} = \\frac{\\sum_{i=1}^n x_i}{n}$\n",
    "*   $\\sigma = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - x_{avg})^2}{(n-1)}}$\n",
    "*   $\\Delta x = \\frac{P_{n,s}\\sigma}{\\sqrt{n}}$\n",
    "*   $x = x_{avg} + \\Delta x, P$\n",
    "*   $\\varepsilon = \\frac{\\Delta x}{x_{avg}} \\cdot 100\\%$\n",
    "*   $dy = \\frac{\\partial y}{\\partial x_1} dx_1 + \\frac{\\partial y}{\\partial x_2} dx_2 + ... + \\frac{\\partial y}{\\partial x_n} dx_n$\n",
    "*   $\\Delta y = \\left|\\frac{\\partial y}{\\partial x_1}\\right|_{x_{avg}} \\cdot \\Delta x_{1avg} + ... + \\left|\\frac{\\partial y}{\\partial x_n}\\right|_{x_{avg}} \\cdot \\Delta x_n$\n",
    "*   $\\sigma_{ny} = \\sqrt{\\left(\\left|\\frac{\\partial y}{\\partial x_1}\\right|_{x_{avg}} \\cdot \\sigma_{nx_1}\\right)^2 + ... + \\left(\\left|\\frac{\\partial y}{\\partial x_n}\\right|_{x_{avg}} \\cdot \\sigma_{nx_n}\\right)^2}$\n",
    "*   $y_{avg} = f(x_{1avg}, x_{2avg}, ... x_{mavg})$\n",
    "*   $\\Delta y = \\frac{\\tau_{P,n}\\sigma_{ny}}{\\sqrt{n}}$\n",
    "*   $y = y_{avg} + \\Delta y, P$\n",
    "\n",
    "---\n",
    "**Additionally:**\n",
    "\n",
    "*   Accuracy\n",
    "*   Precision\n",
    "*   Uncertainty\n",
    "*   Propagation of uncertainty\n",
    "*   Standard deviation\n",
    "*   Probability theory\n",
    "*   Mathematical statistics\n",
    "*   Degrees of freedom\n",
    "*   Normal distribution (Gaussian distribution)\n",
    "*   Absolute error\n",
    "*   Relative uncertainty"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
