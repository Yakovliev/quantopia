
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Goodness of Fit and Chi-Squared Statistic &#8212; Quantopia&#39;:&#39; Physics, Python and Pi</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'math/01_basics/goodness-of-fit-and-chi-squared';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC)" href="aic-and-bic.html" />
    <link rel="prev" title="WLS - Code Examples Part 1" href="weighted-least-squares-code-1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Quantopia':' Physics, Python and Pi - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Quantopia':' Physics, Python and Pi - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Quantopia: Physics, Python, and Pi (Alpha Version)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">MATH</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gradient-operator.html">Gradient</a></li>
<li class="toctree-l1"><a class="reference internal" href="gradient-directional-derivative.html">Directional Derivative</a></li>
<li class="toctree-l1"><a class="reference internal" href="divergence.html">Divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="fourier-transform-01.html">Fourier Transform</a></li>
<li class="toctree-l1"><a class="reference internal" href="least-squares-regression.html">Least Squares Regression, RSS, RMSE, R-squared</a></li>
<li class="toctree-l1"><a class="reference internal" href="least-squares-regression-code.html">Least Squares Regression - Code Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordinary-least-squares.html">Ordinary Least Squares (OLS) Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordinary-least-squares-code.html">Ordinary Least Squares (OLS) Regression - Code Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="variance-covariance.html">Variance and Covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="weighted-least-squares.html">Weighted Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="weighted-least-squares-code-1.html">WLS - Code Examples Part 1</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Goodness of Fit and Chi-Squared Statistic</a></li>
<li class="toctree-l1"><a class="reference internal" href="aic-and-bic.html">Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="weighted-least-squares-code-2.html">WLS - Code Examples Part 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="orthogonal-distance-regression.html">Orthogonal Distance Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PHYSICS</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../physics/continuity-equation-01.html">The Continuity Equation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../physics/continuity-equation-02.html">The Continuity Equation: One-Dimensional Advection of a Density Profile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../physics/ensemble.html">Statistical Ensembles and Liouville’s Theorem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../physics/microcanonical-ensemble.html">Microcanonical Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../physics/fokker-planck-equation-example.html">Fokker-Planck Equation - Example Analysis (preview)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DATA SCIENCE AND MACHINE LEARNING</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../data-science/knn-algorithm.html">K-Nearest Neighbors (KNN) Algorithm (preview)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data-science/naive-bayes.html">Naive Bayes Method (preview)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data-science/logistic-regression.html">Logistic Regression (preview)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/Yakovliev/quantopia/blob/main/book/math/01_basics/goodness-of-fit-and-chi-squared.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Yakovliev/quantopia" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Yakovliev/quantopia/issues/new?title=Issue%20on%20page%20%2Fmath/01_basics/goodness-of-fit-and-chi-squared.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/math/01_basics/goodness-of-fit-and-chi-squared.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Goodness of Fit and Chi-Squared Statistic</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions">Definitions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-chi-squared">Reduced Chi-Squared</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unknown-standard-deviation-for-scipy-optimize-curve-fit">Unknown standard deviation for <code class="docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-the-goodness-of-fit-is-calculated">How the Goodness of Fit is Calculated</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-squared-statistic-for-non-linear-regression">Chi-Squared Statistic for Non-Linear Regression</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="goodness-of-fit-and-chi-squared-statistic">
<h1>Goodness of Fit and Chi-Squared Statistic<a class="headerlink" href="#goodness-of-fit-and-chi-squared-statistic" title="Link to this heading">#</a></h1>
<section id="definitions">
<h2>Definitions<a class="headerlink" href="#definitions" title="Link to this heading">#</a></h2>
<p>The concepts of goodness of fit and the chi-squared statistic are central to the statistical rigor of a least squares fit. Let’s build them from the ground up.</p>
<blockquote>
<div><p>In a general sense, <strong>“goodness of fit”</strong> is a measure of how well a statistical model describes a set of observations. When you fit a curve to data, you’re building a model. “Goodness of fit” is the answer to the question: “How close are the values predicted by my model to the actual data values I measured?”</p>
</div></blockquote>
<p>The fundamental building block for this is the <strong>residual</strong>. For each data point <span class="math notranslate nohighlight">\(i\)</span>, the residual, <span class="math notranslate nohighlight">\(e_i\)</span>, is simply the difference between the observed value (<span class="math notranslate nohighlight">\(y_i\)</span>) and the value predicted by the model (<span class="math notranslate nohighlight">\(f(x_i, \beta)\)</span>):</p>
<div class="math notranslate nohighlight">
\[e_i = y_i - f(x_i, \beta)\]</div>
<p>A perfect fit would have all residuals equal to zero. However, in reality, measurements have uncertainty, and a perfect fit is impossible. Our goal is to find a single number that summarizes all these residuals to tell us if the overall fit is “good enough.”</p>
<p>A simple approach to summarizing the residuals would be to just sum their squares, as in Ordinary Least Squares (OLS):</p>
<div class="math notranslate nohighlight">
\[\text{Sum of Squared Residuals (SSR)} = \sum_{i=1}^{N} e_i^2 = \sum_{i=1}^{N} (y_i - f(x_i, \beta))^2\]</div>
<p>The problem with SSR is that it doesn’t account for the <strong>precision of the individual measurements</strong>. Imagine two different experiments:</p>
<ul class="simple">
<li><p><strong>Experiment A:</strong> Data points are very precise (low uncertainty). A small SSR might still represent a poor fit because the residuals are much larger than the measurement uncertainties.</p></li>
<li><p><strong>Experiment B:</strong> Data points are very noisy (high uncertainty). A large SSR might be a perfectly good fit because the residuals are consistent with the large measurement uncertainties.</p></li>
</ul>
<p>To create a goodness-of-fit metric that is meaningful regardless of the measurement units or precision, we need to <strong>normalize</strong> each residual by its own uncertainty. This is the key idea behind the <span class="math notranslate nohighlight">\(\chi^2\)</span> statistic.</p>
<p><strong>The Derivation:</strong></p>
<ol class="arabic">
<li><p><strong>Define a standardized residual.</strong> For each data point <span class="math notranslate nohighlight">\(i\)</span>, we know its residual <span class="math notranslate nohighlight">\(e_i = y_i - f(x_i, \beta)\)</span> and its measurement uncertainty, quantified by the standard deviation <span class="math notranslate nohighlight">\(\sigma_i\)</span>. Let’s create a new, dimensionless value by dividing the residual by its standard deviation:</p>
<div class="math notranslate nohighlight">
\[\frac{e_i}{\sigma_i} = \frac{y_i - f(x_i, \beta)}{\sigma_i}\]</div>
<p>This new value represents how many standard deviations the observed value is away from the model’s prediction. If this value is close to <span class="math notranslate nohighlight">\(\pm 1\)</span>, the model’s prediction is within one standard deviation of the measurement, which is what we would expect for a good fit.</p>
</li>
<li><p><strong>Sum the squares.</strong> The <strong>chi-squared statistic</strong> (<span class="math notranslate nohighlight">\(\chi^2\)</span>) is defined as the sum of the squares of these standardized residuals. We square them to ensure all values are positive and to give more weight to larger deviations, just as in OLS.</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum_{i=1}^{N} \left( \frac{y_i - f(x_i, \beta)}{\sigma_i} \right)^2\]</div>
</li>
</ol>
<p>This simple formula is the foundation of the <span class="math notranslate nohighlight">\(\chi^2\)</span> test. It is a single number that quantifies the overall discrepancy between the data and the model, scaled by the known measurement uncertainties.</p>
<p>Notice that this is exactly the objective function that the Weighted Least Squares algorithm minimizes. When you provide <code class="docutils literal notranslate"><span class="pre">sigma</span></code> values to <code class="docutils literal notranslate"><span class="pre">curve_fit</span></code>, the function internally calculates the weights as <span class="math notranslate nohighlight">\(w_i = 1/\sigma_i^2\)</span> and minimizes this same sum.</p>
<section id="reduced-chi-squared">
<h3>Reduced Chi-Squared<a class="headerlink" href="#reduced-chi-squared" title="Link to this heading">#</a></h3>
<p>A raw <span class="math notranslate nohighlight">\(\chi^2\)</span> value on its own isn’t very informative because its expected value depends on the number of data points. To make it more meaningful, we use the concept of <strong>degrees of freedom</strong>.</p>
<ul>
<li><p><strong>Degrees of Freedom (<span class="math notranslate nohighlight">\(\nu\)</span>):</strong> This is defined as the number of data points minus the number of parameters you are fitting.</p>
<div class="math notranslate nohighlight">
\[\nu = N - P\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N\)</span>: Number of data points.</p></li>
<li><p><span class="math notranslate nohighlight">\(P\)</span>: Number of parameters in your model.
The degrees of freedom represent the number of independent pieces of information available to test the goodness of fit after the model parameters have been determined.</p></li>
</ul>
</li>
<li><p><strong>Reduced Chi-Squared (<span class="math notranslate nohighlight">\(\chi^2_\nu\)</span>):</strong> To get a normalized measure that is easier to interpret, we divide <span class="math notranslate nohighlight">\(\chi^2\)</span> by the degrees of freedom.</p>
<div class="math notranslate nohighlight">
\[\chi^2_\nu = \frac{\chi^2}{\nu}\]</div>
</li>
</ul>
<p>The interpretation of the reduced chi-squared value is intuitive and powerful:</p>
<ul class="simple">
<li><p><strong><span class="math notranslate nohighlight">\(\chi^2_\nu \approx 1\)</span> (Ideal):</strong> This is the gold standard for a good fit. It means that the total squared deviation of the data from the model is, on average, about what you would expect given your known measurement uncertainties. The residuals are consistent with the random noise you’ve specified with your <code class="docutils literal notranslate"><span class="pre">sigma</span></code> values.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(\chi^2_\nu &gt; 1\)</span> (Poor Fit or Underestimated Errors):</strong> This indicates that the residuals are larger than what your uncertainties would predict. The model is a poor fit for the data. This could be because:</p>
<ol class="arabic simple">
<li><p>The model function <code class="docutils literal notranslate"><span class="pre">f(x)</span></code> is simply incorrect and doesn’t describe the underlying physical process.</p></li>
<li><p>Your measurement uncertainties (<code class="docutils literal notranslate"><span class="pre">sigma</span></code>) were underestimated, and the data is actually more noisy than you assumed.</p></li>
</ol>
</li>
<li><p><strong><span class="math notranslate nohighlight">\(\chi^2_\nu &lt; 1\)</span> (“Too Good” Fit or Overestimated Errors):</strong> This suggests that the model fits the data <em>better</em> than would be expected by random chance alone. This could be a sign that:</p>
<ol class="arabic simple">
<li><p>Your measurement uncertainties (<code class="docutils literal notranslate"><span class="pre">sigma</span></code>) were overestimated.</p></li>
<li><p>The model is over-fitting the data by matching the random noise instead of the underlying trend.</p></li>
<li><p>The data might have been cherry-picked, or there’s a systematic error in how the uncertainties were determined.</p></li>
</ol>
</li>
</ul>
<p>In summary, the chi-squared statistic provides a rigorous, quantitative way to answer the question of “goodness of fit” by comparing the observed discrepancies between the model and the data against the known uncertainties of the data points themselves.</p>
</section>
</section>
<section id="unknown-standard-deviation-for-scipy-optimize-curve-fit">
<h2>Unknown standard deviation for <code class="docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code><a class="headerlink" href="#unknown-standard-deviation-for-scipy-optimize-curve-fit" title="Link to this heading">#</a></h2>
<p>There is an the apparent paradox: the <code class="docutils literal notranslate"><span class="pre">chi-squared</span></code> formula needs <code class="docutils literal notranslate"><span class="pre">sigma</span></code>, but the <code class="docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code> function calculates a “goodness of fit” without it.</p>
<p>The answer lies in a clever statistical trick <code class="docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code> uses when you don’t provide explicit uncertainties.</p>
<p>When you skip the <code class="docutils literal notranslate"><span class="pre">sigma</span></code> parameter, <code class="docutils literal notranslate"><span class="pre">curve_fit</span></code> doesn’t assume that the errors are zero. Instead, it makes a different, less strict assumption: it assumes that all your data points have the same <strong>unknown</strong> standard deviation, <span class="math notranslate nohighlight">\(\sigma_{unknown}\)</span>.</p>
<p>This is a specific form of the homoscedasticity assumption. Since the standard deviation is the same for every point, you don’t need to specify it for the purpose of finding the best-fit parameters, because all the weights would be equal (<span class="math notranslate nohighlight">\(w_i = 1/\sigma_{unknown}^2\)</span>). As we discussed, a constant weight doesn’t change the location of the minimum of the sum of squares.</p>
<section id="how-the-goodness-of-fit-is-calculated">
<h3>How the Goodness of Fit is Calculated<a class="headerlink" href="#how-the-goodness-of-fit-is-calculated" title="Link to this heading">#</a></h3>
<p>Even though the standard deviation is unknown, we can <strong>estimate</strong> it from the data itself after the fit is complete. The logic is as follows:</p>
<ol class="arabic">
<li><p><strong>Perform a standard OLS fit:</strong> The algorithm finds the parameters that minimize the plain old Sum of Squared Residuals (SSR):</p>
<div class="math notranslate nohighlight">
\[\text{SSR} = \sum_{i=1}^{N} (y_i - f(x_i, \beta))^2\]</div>
</li>
<li><p><strong>Estimate the Variance:</strong> The best estimate for the unknown variance, <span class="math notranslate nohighlight">\(\sigma_{unknown}^2\)</span>, is the average squared residual. This is known as the <strong>residual variance</strong> or <strong>Mean Squared Error (MSE)</strong>, and it’s calculated by dividing the SSR by the degrees of freedom (<span class="math notranslate nohighlight">\(\nu = N-P\)</span>):</p>
<div class="math notranslate nohighlight">
\[\hat{\sigma}^2_{unknown} = \frac{\text{SSR}}{\nu} = \frac{\sum_{i=1}^{N} (y_i - f(x_i, \beta))^2}{N-P}\]</div>
<p>This value, <span class="math notranslate nohighlight">\(\hat{\sigma}^2_{unknown}\)</span>, is a measure of the average scatter of your data points around the fitted curve.</p>
</li>
<li><p><strong>The Scaling Factor:</strong> The reduced chi-squared value is conceptually <span class="math notranslate nohighlight">\(\chi^2/\nu\)</span>. When no <code class="docutils literal notranslate"><span class="pre">sigma</span></code> is provided, the chi-squared value is technically calculated with <span class="math notranslate nohighlight">\(\sigma_i = 1\)</span> for all points. So, <span class="math notranslate nohighlight">\(\chi^2 = \text{SSR}\)</span>. Therefore, the reduced chi-squared is simply <span class="math notranslate nohighlight">\(\text{SSR}/\nu\)</span>. This value is used as the scaling factor for the covariance matrix. Link: <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html</a></p>
<p>More formally, the <code class="docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code> documentation states that when <code class="docutils literal notranslate"><span class="pre">absolute_sigma=False</span></code>, the covariance matrix is scaled by a factor that demands the reduced chi-squared for the optimal parameters equals unity. This is equivalent to scaling the covariance matrix by <span class="math notranslate nohighlight">\(\text{SSR} / \nu\)</span>. Mathematically,</p>
<p><code class="docutils literal notranslate"><span class="pre">pcov(absolute_sigma=False)</span> <span class="pre">=</span> <span class="pre">pcov(absolute_sigma=True)</span> <span class="pre">*</span> <span class="pre">chisq(popt)/(M-N)</span></code></p>
<p>For more details, review the documentation: <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html</a></p>
</li>
</ol>
<p>In essence, when you skip the <code class="docutils literal notranslate"><span class="pre">sigma</span></code> parameter, the function does two things:</p>
<ol class="arabic simple">
<li><p>It assumes all points have the same, unknown uncertainty.</p></li>
<li><p>It uses the <strong>observed scatter of the data</strong> (quantified by the residual variance, <span class="math notranslate nohighlight">\(\text{SSR}/\nu\)</span>) as a post-hoc <em>estimate</em> of that unknown uncertainty.</p></li>
</ol>
<p>This estimate of the uncertainty is then used to calculate the standard errors of your fitted parameters. This is a robust approach when you don’t have prior knowledge of your measurement errors, but it’s not as statistically rigorous as providing a known uncertainty via the <code class="docutils literal notranslate"><span class="pre">sigma</span></code> parameter. The parameter uncertainties you get are a reflection of how well your model explains the observed variation in your data, rather than being based on a known, independent measure of your experimental precision.</p>
</section>
</section>
<section id="chi-squared-statistic-for-non-linear-regression">
<h2>Chi-Squared Statistic for Non-Linear Regression<a class="headerlink" href="#chi-squared-statistic-for-non-linear-regression" title="Link to this heading">#</a></h2>
<p>The use of reduced chi-squared statistics for non-linear models involves <strong>significant interpretational challenges</strong> that require careful consideration. While the statistic can still be calculated, its meaning and reliability become more complex compared to linear models.</p>
<p>The reduced chi-squared (<span class="math notranslate nohighlight">\(\chi^2_v\)</span>) is defined as the chi-squared statistic (<span class="math notranslate nohighlight">\(\chi^2\)</span>) divided by the number of degrees of freedom (<span class="math notranslate nohighlight">\(\nu\)</span>):</p>
<div class="math notranslate nohighlight">
\[\chi^2_v = \frac{\chi^2}{\nu}\]</div>
<p>The chi-squared statistic itself, a measure of how well a model fits the data, is straightforward to calculate for <strong>both linear and non-linear models</strong>:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum_{i=1}^{N} \frac{(O_i - E_i)^2}{\sigma_i^2} = \sum_{i=1}^{N} \left( \frac{y_i - f(x_i, \beta)}{\sigma_i} \right)^2\]</div>
<p>Here, <span class="math notranslate nohighlight">\(O_i\)</span> are the observed data points, <span class="math notranslate nohighlight">\(E_i\)</span> are the expected values from the model, and <span class="math notranslate nohighlight">\(\sigma_i\)</span> are the measurement uncertainties.</p>
<p>The conventional calculation for degrees of freedom (<span class="math notranslate nohighlight">\(\nu\)</span>) is the number of data points (<span class="math notranslate nohighlight">\(N\)</span>) minus the number of parameters (<span class="math notranslate nohighlight">\(P\)</span>) that were fitted to the data (<span class="math notranslate nohighlight">\(\nu = N - P\)</span>).</p>
<ul class="simple">
<li><p><strong>For linear models</strong>, this approach is well-established. The number of fitted parameters (<span class="math notranslate nohighlight">\(P\)</span>) corresponds directly to the model parameters (e.g., slope and intercept in linear regression). Because the model is a linear superposition of basis functions, the relationship between parameters and the chi-squared value is quadratic, making the parameters mathematically independent and the degrees of freedom calculation straightforward.</p></li>
<li><p><strong>For non-linear models</strong>, several complications arise that challenge the traditional interpretation:</p>
<ul>
<li><p>The relationship between parameters and data becomes more complex</p></li>
<li><p>Parameters can exhibit strong correlations and interdependencies</p></li>
<li><p>Small changes in one parameter may have disproportionate effects on others</p></li>
<li><p>The concept of “effective degrees of freedom” may differ significantly from the simple parameter count</p></li>
<li><p>The number of constraints imposed by the fit may not equal the number of parameters</p></li>
</ul>
</li>
</ul>
<p><strong>You can still calculate</strong> the chi-squared (<span class="math notranslate nohighlight">\(\chi^2\)</span>) value to find best-fit parameters for your non-linear function through weighted least-squares fitting. Many statistical software packages routinely report reduced chi-squared values for nonlinear fits.</p>
<p><strong>However, exercise caution when interpreting</strong> the reduced chi-squared (<span class="math notranslate nohighlight">\(\chi^2_\nu\)</span>) for nonlinear models:</p>
<ul class="simple">
<li><p>A value close to 1 does not guarantee a good model, as the degrees of freedom calculation may not be strictly valid</p></li>
<li><p>The traditional interpretation guidelines may be less reliable</p></li>
<li><p>Consider the result as one piece of evidence rather than a definitive assessment</p></li>
</ul>
<p><strong>Bottom line</strong>: Reduced chi-squared can be calculated for nonlinear models and may provide useful information, but its interpretation is less straightforward than for linear cases, and it should be used alongside other model assessment tools for more reliable conclusions. It’s also recommended to use information criteria like the <strong>Akaike Information Criterion (AIC)</strong> or <strong>Bayesian Information Criterion (BIC)</strong>, which penalize model complexity in a more robust way and allow comparison between different models.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./math\01_basics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="weighted-least-squares-code-1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">WLS - Code Examples Part 1</p>
      </div>
    </a>
    <a class="right-next"
       href="aic-and-bic.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions">Definitions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-chi-squared">Reduced Chi-Squared</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unknown-standard-deviation-for-scipy-optimize-curve-fit">Unknown standard deviation for <code class="docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-the-goodness-of-fit-is-calculated">How the Goodness of Fit is Calculated</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-squared-statistic-for-non-linear-regression">Chi-Squared Statistic for Non-Linear Regression</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Vladyslav Yakovliev
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>